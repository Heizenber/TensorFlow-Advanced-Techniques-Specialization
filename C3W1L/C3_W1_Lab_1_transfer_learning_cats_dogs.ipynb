{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"C3_W1_Lab_1_transfer_learning_cats_dogs.ipynb","provenance":[{"file_id":"1JGWdKozbc3dbRzFUtqqCLXbnsFg7EPtv","timestamp":1608960214453}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fYJqjq66JVQQ"},"source":["# Basic transfer learning with cats and dogs data\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0oWuHhhcJVQQ"},"source":["### Import tensorflow"]},{"cell_type":"code","metadata":{"id":"ioLbtB3uGKPX","executionInfo":{"status":"ok","timestamp":1608960283934,"user_tz":-480,"elapsed":767,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gjfMJAHPJVQR"},"source":["### Import modules and download the cats and dogs dataset."]},{"cell_type":"code","metadata":{"id":"y23ucAFLoHop","executionInfo":{"status":"ok","timestamp":1608960297268,"user_tz":-480,"elapsed":14094,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}}},"source":["import urllib.request\n","import os\n","import zipfile\n","import random\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.optimizers import RMSprop\n","from shutil import copyfile\n","\n","\n","data_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n","data_file_name = \"catsdogs.zip\"\n","download_dir = '/tmp/'\n","urllib.request.urlretrieve(data_url, data_file_name)\n","zip_ref = zipfile.ZipFile(data_file_name, 'r')\n","zip_ref.extractall(download_dir)\n","zip_ref.close()\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JNVXCUNUJVQR"},"source":["Check that the dataset has the expected number of examples."]},{"cell_type":"code","metadata":{"id":"AwMoZHxWOynx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608960297270,"user_tz":-480,"elapsed":14094,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}},"outputId":"702b5f59-c22c-4071-d586-b95e9d6d5efc"},"source":["print(\"Number of cat images:\",len(os.listdir('/tmp/PetImages/Cat/')))\n","print(\"Number of dog images:\", len(os.listdir('/tmp/PetImages/Dog/')))\n","\n","# Expected Output:\n","# Number of cat images: 12501\n","# Number of dog images: 12501"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Number of cat images: 12501\n","Number of dog images: 12501\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_0riaptkJVQR"},"source":["Create some folders that will store the training and test data.\n","- There will be a training folder and a testing folder.\n","- Each of these will have a subfolder for cats and another subfolder for dogs."]},{"cell_type":"code","metadata":{"id":"qygIo4W5O1hQ","executionInfo":{"status":"ok","timestamp":1608960297271,"user_tz":-480,"elapsed":14093,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}}},"source":["try:\n","    os.mkdir('/tmp/cats-v-dogs')\n","    os.mkdir('/tmp/cats-v-dogs/training')\n","    os.mkdir('/tmp/cats-v-dogs/testing')\n","    os.mkdir('/tmp/cats-v-dogs/training/cats')\n","    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n","    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n","    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n","except OSError:\n","    pass"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ZHD_c-sJVQR"},"source":["### Split data into training and test sets\n","\n","- The following code put first checks if an image file is empty (zero length)\n","- Of the files that are not empty, it puts 90% of the data into the training set, and 10% into the test set."]},{"cell_type":"code","metadata":{"id":"M90EiIu0O314","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608960320799,"user_tz":-480,"elapsed":37618,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}},"outputId":"ab1e89d4-0848-4042-dcb1-3d24a4fad87a"},"source":["import random\n","from shutil import copyfile\n","def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n","    files = []\n","    for filename in os.listdir(SOURCE):\n","        file = SOURCE + filename\n","        if os.path.getsize(file) > 0:\n","            files.append(filename)\n","        else:\n","            print(filename + \" is zero length, so ignoring.\")\n","\n","    training_length = int(len(files) * SPLIT_SIZE)\n","    testing_length = int(len(files) - training_length)\n","    shuffled_set = random.sample(files, len(files))\n","    training_set = shuffled_set[0:training_length]\n","    testing_set = shuffled_set[training_length:]\n","\n","    for filename in training_set:\n","        this_file = SOURCE + filename\n","        destination = TRAINING + filename\n","        copyfile(this_file, destination)\n","\n","    for filename in testing_set:\n","        this_file = SOURCE + filename\n","        destination = TESTING + filename\n","        copyfile(this_file, destination)\n","\n","\n","CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n","TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n","TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n","DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n","TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n","TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n","\n","split_size = .9\n","split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n","split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n","\n","# Expected output\n","# 666.jpg is zero length, so ignoring\n","# 11702.jpg is zero length, so ignoring"],"execution_count":5,"outputs":[{"output_type":"stream","text":["666.jpg is zero length, so ignoring.\n","11702.jpg is zero length, so ignoring.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KMx_pePuJVQR"},"source":["Check that the training and test sets are the expected lengths."]},{"cell_type":"code","metadata":{"id":"cl8sQpM1O9xK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608960320802,"user_tz":-480,"elapsed":37619,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}},"outputId":"d122bb9f-0f52-4119-8356-803537a9b939"},"source":["\n","print(\"Number of training cat images\", len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n","print(\"Number of training dog images\", len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n","print(\"Number of testing cat images\", len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n","print(\"Number of testing dog images\", len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n","\n","# expected output\n","# Number of training cat images 11250\n","# Number of training dog images 11250\n","# Number of testing cat images 1250\n","# Number of testing dog images 1250"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Number of training cat images 11250\n","Number of training dog images 11250\n","Number of testing cat images 1250\n","Number of testing dog images 1250\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pNz89__rJVQR"},"source":["### Data augmentation (try adjusting the parameters)!\n","\n","Here, you'll use the `ImageDataGenerator` to perform data augmentation.  \n","- Things like rotating and flipping the existing images allows you to generate training data that is more varied, and can help the model generalize better during training.  \n","- You can also use the data generator to apply data augmentation to the validation set.\n","\n","You can use the default parameter values for a first pass through this lab.\n","- Later, try to experiment with the parameters of `ImageDataGenerator` to improve the model's performance.\n","- Try to drive reach 99.9% validation accuracy or better."]},{"cell_type":"code","metadata":{"id":"TVO1l8vAPE14","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608960320803,"user_tz":-480,"elapsed":37617,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}},"outputId":"999f656e-289a-4ef4-e87c-6a519946d001"},"source":["\n","TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n","# Experiment with your own parameters to reach 99.9% validation accuracy or better\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","      rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n","                                                    batch_size=100,\n","                                                    class_mode='binary',\n","                                                    target_size=(150, 150))\n","\n","VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n","                                                              batch_size=100,\n","                                                              class_mode='binary',\n","                                                              target_size=(150, 150))\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found 22498 images belonging to 2 classes.\n","Found 2500 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WchwDzWNJVQR"},"source":["### Get and prepare the model\n","\n","You'll be using the `InceptionV3` model.  \n","- Since you're making use of transfer learning, you'll load the pre-trained weights of the model.\n","- You'll also freeze the existing layers so that they aren't trained on your downstream task with the cats and dogs data.\n","- You'll also get a reference to the last layer, 'mixed7' because you'll add some layers after this last layer."]},{"cell_type":"code","metadata":{"id":"tiPK1LlMOvm7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608960336079,"user_tz":-480,"elapsed":52891,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}},"outputId":"0c324693-ddff-48f9-a844-960d709f32de"},"source":["weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n","weights_file = \"inception_v3.h5\"\n","urllib.request.urlretrieve(weights_url, weights_file)\n","\n","# Instantiate the model\n","pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n","                                include_top=False,\n","                                weights=None)\n","\n","# load pre-trained weights\n","pre_trained_model.load_weights(weights_file)\n","\n","# freeze the layers\n","for layer in pre_trained_model.layers:\n","    layer.trainable = False\n","\n","# pre_trained_model.summary()\n","\n","last_layer = pre_trained_model.get_layer('mixed7')\n","print('last layer output shape: ', last_layer.output_shape)\n","last_output = last_layer.output\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["last layer output shape:  (None, 7, 7, 768)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3edBz_IxJVQR"},"source":["### Add layers\n","Add some layers that you will train on the cats and dogs data.\n","- `Flatten`: This will take the output of the `last_layer` and flatten it to a vector.\n","- `Dense`: You'll add a dense layer with a relu activation.\n","- `Dense`: After that, add a dense layer with a sigmoid activation.  The sigmoid will scale the output to range from 0 to 1, and allow you to interpret the output as a prediction between two categories (cats or dogs).\n","\n","Then create the model object."]},{"cell_type":"code","metadata":{"id":"oDidHXO1JVQR","executionInfo":{"status":"ok","timestamp":1608960336080,"user_tz":-480,"elapsed":52889,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}}},"source":["# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(last_output)\n","# Add a fully connected layer with 1,024 hidden units and ReLU activation\n","x = layers.Dense(1024, activation='relu')(x)\n","# Add a final sigmoid layer for classification\n","x = layers.Dense(1, activation='sigmoid')(x)\n","\n","model = Model(pre_trained_model.input, x)\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"asCm8okXJVQR"},"source":["### Train the model\n","Compile the model, and then train it on the test data using `model.fit`\n","- Feel free to adjust the number of epochs.  This project was originally designed with 20 epochs.\n","- For the sake of time, you can use fewer epochs (2) to see how the code runs.\n","- You can ignore the warnings about some of the images having corrupt EXIF data. Those will be skipped."]},{"cell_type":"code","metadata":{"id":"3nxUncKWPRhR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608960671690,"user_tz":-480,"elapsed":388497,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}},"outputId":"7613eaa1-df82-4014-9ae8-5e37430cbb75"},"source":["\n","# compile the model\n","model.compile(optimizer=RMSprop(lr=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","\n","# train the model (adjust the number of epochs from 1 to improve performance)\n","history = model.fit(\n","            train_generator,\n","            validation_data=validation_generator,\n","            epochs=2,\n","            verbose=1)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n"," 29/225 [==>...........................] - ETA: 2:11 - loss: 0.8863 - acc: 0.7428"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["225/225 [==============================] - 172s 725ms/step - loss: 0.3755 - acc: 0.8680 - val_loss: 0.0997 - val_acc: 0.9664\n","Epoch 2/2\n","225/225 [==============================] - 162s 722ms/step - loss: 0.1572 - acc: 0.9363 - val_loss: 0.0988 - val_acc: 0.9700\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H6Oo6kM-JVQR"},"source":["### Visualize the training and validation accuracy\n","\n","You can see how the training and validation accuracy change with each epoch on an x-y plot."]},{"cell_type":"code","metadata":{"id":"erDopoQ5eNL7","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1608960671691,"user_tz":-480,"elapsed":388496,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}},"outputId":"29142e39-81b2-4b2f-ba2e-a12026cb4b73"},"source":["%matplotlib inline\n","\n","import matplotlib.image  as mpimg\n","import matplotlib.pyplot as plt\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc=history.history['acc']\n","val_acc=history.history['val_acc']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","epochs=range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n","plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n","plt.title('Training and validation accuracy')\n","plt.figure()\n","\n"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]},"execution_count":11},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"xKc_1Qm8JVQR"},"source":["### Predict on a test image\n","\n","You can upload any image and have the model predict whether it's a dog or a cat.\n","- Find an image of a dog or cat\n","- Run the following code cell.  It will ask you to upload an image.\n","- The model will print \"is a dog\" or \"is a cat\" depending on the model's prediction."]},{"cell_type":"code","metadata":{"id":"_0R9fsf4w29e","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1608960801334,"user_tz":-480,"elapsed":11744,"user":{"displayName":"Jeremy Lai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjL3hpxYpxmxjk8399-BRp8ehxCWbj9VneRHT9g0A=s64","userId":"16144470389413821702"}},"outputId":"c5c6233f-0aa8-4240-e756-f5c635f2141e"},"source":["import numpy as np\n","from google.colab import files\n","from keras.preprocessing import image\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n"," \n","  # predicting images\n","  path = '/content/' + fn\n","  img = image.load_img(path, target_size=(150, 150))\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","\n","  image_tensor = np.vstack([x])\n","  classes = model.predict(image_tensor)\n","  print(classes)\n","  print(classes[0])\n","  if classes[0]>0.5:\n","    print(fn + \" is a dog\")\n","  else:\n","    print(fn + \" is a cat\")"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-4fe9a9ad-cd78-4c4c-8336-e497d028658d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-4fe9a9ad-cd78-4c4c-8336-e497d028658d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving 10015.jpg to 10015.jpg\n","[[1.]]\n","[1.]\n","10015.jpg is a dog\n"],"name":"stdout"}]}]}